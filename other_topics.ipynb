{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0654e16d",
   "metadata": {},
   "source": [
    "## Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77c12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8023a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_32140\\3513586721.py:1: DeprecationWarning: Use [`ChatGoogleGenerativeAI`][langchain_google_genai.ChatGoogleGenerativeAI] instead.\n",
      "  llm = ChatVertexAI(model_name=\"gemini-2.5-flash-lite\")\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_32140\\3513586721.py:1: LangChainDeprecationWarning: The class `ChatVertexAI` was deprecated in LangChain 3.2.0 and will be removed in 4.0.0. An updated version of the class exists in the `langchain-google-genai package and should be used instead. To use it run `pip install -U `langchain-google-genai` and import as `from `langchain_google_genai import ChatGoogleGenerativeAI``.\n",
      "  llm = ChatVertexAI(model_name=\"gemini-2.5-flash-lite\")\n"
     ]
    }
   ],
   "source": [
    "llm = ChatVertexAI(model_name=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafb3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\", \"What is capital of {country}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d2fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca4c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'country': 'France'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9bf8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b40586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 10, 'candidates_token_count': 8, 'total_token_count': 18, 'prompt_tokens_details': [{'modality': 1, 'token_count': 10}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0008943912689574063, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd47-9e31-7d91-9990-c7439a14aaf5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 8, 'total_tokens': 18, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e8f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know i want text out which is a string\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain_with_output = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1889fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_with_output.invoke({'country': 'France'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c708fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f60d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a2704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant responding always in json format\"),\n",
    "    (\"human\", \"What is capital of {country}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "709d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e459cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"country\": \"France\",\\n  \"capital\": \"Paris\"\\n}\\n```', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 15, 'candidates_token_count': 24, 'total_token_count': 39, 'prompt_tokens_details': [{'modality': 1, 'token_count': 15}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 24}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.001756157570828994, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd4b-b91e-7953-8124-c0d7692b5f5e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 24, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'country': 'France'})\n",
    "print(type(response))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a1a67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "#parser = JsonOutputParser()\n",
    "\n",
    "chain_with_output = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a89610be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'France', 'capital': 'Paris'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain_with_output.invoke({'country': 'France'})\n",
    "print(type(response))\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63b59d",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2484fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant \"),\n",
    "    (\"human\", \"my name is khaja\"),\n",
    "    (\"human\", \"What is capital of {country}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbf2dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64d44691",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7768ad62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 16, 'candidates_token_count': 8, 'total_token_count': 24, 'prompt_tokens_details': [{'modality': 1, 'token_count': 16}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.006595118436962366, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd56-f32e-7c33-b6a6-3ea4112840f6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 8, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    'country': 'France'\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "663206ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append((\"ai\", response.content))\n",
    "messages.append((\"human\", \"what is my name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a4551f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is **Khaja**.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 28, 'candidates_token_count': 7, 'total_token_count': 35, 'prompt_tokens_details': [{'modality': 1, 'token_count': 28}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 7}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.1873471736907959, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd57-11a1-75a3-8f62-4ad81a4afc93-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 28, 'output_tokens': 7, 'total_tokens': 35, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt | llm\n",
    "chain.invoke({\n",
    "    'country': 'France'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73876fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817c086",
   "metadata": {},
   "source": [
    "## By default the interactions with llm are stateless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51b5e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant \"),\n",
    "    (\"human\", \"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8284a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "response  = chain.invoke({\n",
    "    'question': 'what is capital of france'\n",
    "})\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91d42041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I do not have a memory of past interactions or \"attempts.\" I am a large language model, trained by Google. Therefore, I can't \"find\" a capital in a previous attempt because I don't retain that kind of personal history.\n",
      "\n",
      "However, if you'd like to know the capital of a specific country, or if you have a question about capitals, I'd be happy to help!\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {'question': 'Which country did you find capital in last attempt'}\n",
    ")\n",
    "response.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6348005",
   "metadata": {},
   "source": [
    "### Lets try making the interaction stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ead211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant \"),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1004e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage for memory across session.\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "STORE = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in STORE:\n",
    "        STORE[session_id] = InMemoryChatMessageHistory()\n",
    "    return STORE[session_id]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04cf3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fcc1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions\n",
    "config_1 = { \"configurable\" : {\"session_id\": \"examiner-1\"} }\n",
    "\n",
    "config_2 = { \"configurable\": {\"session_id\": \"examiner-2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f9c36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_memory.invoke(\n",
    "    {\"question\": \"What is capital of France\"}, config=config_1\n",
    ")\n",
    "# paris\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "669da07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examiner-1': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is capital of France', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 11, 'candidates_token_count': 8, 'total_token_count': 19, 'prompt_tokens_details': [{'modality': 1, 'token_count': 11}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0019236402586102486, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd7d-e0b4-7412-abf3-887275d913d2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 8, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}})])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "561a9886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have not searched for any country's capital previously. I am a large language model, an AI, and I don't have personal browsing history or memory of past interactions in that way.\n",
      "\n",
      "However, if you're referring to the capital I just provided, the country was **France**.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_memory.invoke(\n",
    "    {\"question\": \"What is country which you have previously searched for capital\"}, \n",
    "    config=config_1\n",
    ")\n",
    "\n",
    "# france\n",
    "response.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0be82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examiner-1': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is capital of France', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 11, 'candidates_token_count': 8, 'total_token_count': 19, 'prompt_tokens_details': [{'modality': 1, 'token_count': 11}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 8}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0019236402586102486, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd7d-e0b4-7412-abf3-887275d913d2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 8, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='What is country which you have previously searched for capital', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I have not searched for any country's capital previously. I am a large language model, an AI, and I don't have personal browsing history or memory of past interactions in that way.\\n\\nHowever, if you're referring to the capital I just provided, the country was **France**.\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 29, 'candidates_token_count': 61, 'total_token_count': 90, 'prompt_tokens_details': [{'modality': 1, 'token_count': 29}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 61}], 'thoughts_token_count': 0, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.41554300902319735, 'model_provider': 'google_vertexai', 'model_name': 'gemini-2.5-flash-lite'}, id='lc_run--019bfd7e-a26b-7883-beda-a68e432834bc-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 29, 'output_tokens': 61, 'total_tokens': 90, 'input_token_details': {'cache_read': 0}})])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "005cdae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I am a large language model, trained by Google. I do not have memory of past searches or personal experiences. Therefore, I have not \"previously searched for a capital\" in the way a human would.\n",
      "\n",
      "My knowledge about countries and their capitals comes from the vast dataset I was trained on. I can access and process this information to answer your questions.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_memory.invoke(\n",
    "    {\"question\": \"What is country which you have previously searched for capital\"}, \n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "# i dont know\n",
    "response.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
